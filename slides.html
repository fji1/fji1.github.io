<!DOCTYPE html>
<html>
  <head>
    <title>Apply conditional distributions to individuals</title>
    <meta charset="utf-8">
    <meta name="author" content="Feng Ji" />
    <link href="libs/remark-css/example.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Apply conditional distributions to individuals
## Using latent variable models
### Feng Ji
### 2017/04/24

---



background-image: url(http://rnorm.me/Example.svg)
background-position: 50% 95%
background-size: 600px
### The properties of large psychological assessments (e.g. WJ IV, WISC/WAIS IV)

- Multiple tests
- Complicated relations


???
So my thesis is titled apply conditional distributions to individuals, using latent variable models.
My thesis is aimed to solve the problem that clininians come across in their day rountine when conducting psychological assessment and making clinical judgements.
Psychological assessment is a process of testing that uses a combination of techniques to help arrive at some hypotheses about a person and their behavior, personality and capabilities. 

For example, Woodcock-Johnson IV is a wildly used assessment battery that assess both cognitive abilities and academic achievements.
For this kind of assessment, we should notice that we have to combine multivariate information together to make decisions.
Be sides the multiple tests, we should know the relations between different tests are complicated as the SEM plot, which illustrate only part of WJ IV.
- Processing Speed (Gs): is the ability to perform automatic cognitive tasks, particularly when measured under pressure to maintain focused attention.
- Comprehension-Knowledge (Gc): includes the breadth and depth of a person's acquired knowledge, the ability to communicate one's knowledge, and the ability to reason using previously learned experiences or procedures.
- Fluid reasoning (Gf): includes the broad ability to reason, form concepts, and solve problems using unfamiliar information or novel procedures.
---
background-image: url(http://rnorm.me/5.png)
---
background-image: url(http://rnorm.me/6.png)

---
background-image: url(http://rnorm.me/0.svg)
background-position: 50% 80%
background-size: 600px
# One simplified case
- Learning disability is defined by having generally intact cognitive
abilities but specific cognitive weakness(PA) explains the academic deficit(Reading Decoding).
- Does this cognitive weakness really explain the academic deficit?
???
Here is one simplified case that clinians may come across when making decision about learning disability, learning disability is defined by having generally intact cognitive
abilities but specific cognitive weaknesses cognitive processing deficits that explain the academic weakness. So lets say we have reading scores phonological awareness is the ability to hear phonemes and sounds distinctly people who have difficulty hearing sounds within words distinctly have difficulty understanding how the sounds correspond to letters and it makes it difficult to read this person has a 75 phonological awareness also at the bottom 5%. So for most of clinians if they saw a parttern like this, they may think their job is done that phonological awareness is theoretically related to reading decoding is much lower than GC and is consistent with reading decoding. This explanation correspond our intuition very well.

---
background-image: url(http://rnorm.me/1.svg)
`\(Reading\)` `\(Decoding\)` = `\(b_0\)` + `\(b_1Gc\)` + `\(b_2Phonological\)` `\(Awareness\)` + `\(error\)`

???
1. Human beings are not born to process probabilistic information e.g. Bayes stats and confusion table (e.g. Type I and Type II errors).
2. e.g2. T test is easy to interpret, one way ANOVA is getting a little bit harder, Three-way ANOVA is even harder.
??? 
The aim of my current project is to solve a common problem that clinicians come across in their day routine.
---
background-image: url(http://rnorm.me/3.jpg)

---
background-image: url(http://rnorm.me/4.svg)
background-size: 900px

*Move into latent level - even more misleading*
???
Just one multiple regression could be misleading, what if in real life we have a full batter to make decisions with and multipe outcome variables. What if we would like to know how this individual does on this three variables, how likely we have this kind of individual in population if we consider, lets say, condition on this cognitive scores combined together.
---
# Problems &amp; Solutions
- Human beings do not combine information of multiple variables well:(
&gt; Mahalanobis Distance:)


- Human beings do not reason well with probability:(
&gt; Conditional Probility:)

- Doing stats is painful and learning curve is steep:(
&gt; Software solution to automate the whole process:)
???
- Things are getting harder when we have multiple variables and even multiple outcomes
- Intuition is against probility (that is why casino can always make money, we think we can beat them but got beaten very badly)
- We could quantify the how unusual we would observe the profile in population
---

&lt;iframe src="http://students.brown.edu/seeing-theory/compound-probability/index.html#third" width="100%" height="700px"&gt;&lt;/iframe&gt;
- Conditional Distribution
---
&lt;iframe src="http://rnorm.me/RGLmodel.html" width="100%" height="500px"&gt;&lt;/iframe&gt;
- The Mahalanobis Distance is a generalized multidimensional way to measure the distance between two vectors in standard deviation units. 
$$d_M = \sqrt{(x - \mu)' C^{-1} (x - \mu)  } $$
---
# Conditional Mahalanobis Distance&lt;sup&gt;1&lt;/sup&gt;
.footnote[
[1] Schneider, W. J. (2017). Geometric Representation of Composite Scores and Profile Variability. Unpublished manuscript.
]

$$d_{cM} = \sqrt{(Z_o - \hat{Z_o})' R_o^{-1} (Z_o - \hat{Z_o})} $$
$$d_M^2 \sim \chi^2(k -c) $$

---
# Applications
1. Help clinicians understand implications of the model.

2. Identify situations in which more testing is needed.
---
# Goal of Current Study
1. Use simulated data to verify the proposed method performs works as intended

2. Choose from different latent score estimation methods to be used in our method

3.	Illustrate how to explain a profile in SEM for individuals to help clinicians make
educated judgments.

4.	Provide software solution to automate the process.
---
### Goal 1: Use simulated data to verify the proposed method works as intended

- Use simulations to validate if the method's probabilities are accurate.

- Investigate the conditions in which the conditional Mahalanobis distance is accurate.


???

For example, if the method says that there is a 5% chance that a latent score is greater than 100, the simulations will show if that is indeed the case.
---
# Goal 2: Comparison of different Latent score estimation methods

1. Thurstone: Regression-based least squares method&lt;sup&gt;1&lt;/sup&gt;

2. Bartlett's approach: Least squares method with correction of covariance between factors&lt;sup&gt;2&lt;/sup&gt;

3. Empirical Bayes random effects estimates&lt;sup&gt;3&lt;/sup&gt; 



.footnote[
[1] Thurstone, L. L. (1935). The vectors of the mind. Chicago, IL: University of Chicago Press.

[2] Bartlett, M. S. (1937). The statistical conception of mental factors. *British Journal of Psychology*, 28, 97-104.

[3] Estabrook, R., &amp; Neale, M. (2013). A comparison of factor score estimation methods in the presence of missing data: Reliability and an application to nicotine dependence. *Multivariate Behavioral Research*, 48(1), 1-27.
]
???
*Difference between Regression Scores and Sum/`Weighted Sum`*
Thurstone (1935) used a least squares regression
approach to predict factor score(s). Regression factor
scores predict the location of each individual on the
factor or component. This procedure differs from the
non-refined weighted sum method, in that the weighed
sum non-refined procedure reflects the extent to which
the factor or component estimated is manifested by each
individual case; the method does not use an underlying
model to predict an "optimal" factor score.

*Regression Scores*
Following regression terminology, with this
method, independent variables in the regression
equation are the standardized observed values of the
items in the estimated factors or components. These
predictor variables are weighted by regression
coefficients, which are obtained by multiplying the
inverse of the observed variable correlation matrix by
the matrix of factor loadings and, in the case of oblique
factors, the factor correlation matrix. 

*Batlett*
Bartlett factor scores are computed by multiplying
the row vector of observed variables, by the inverse of
the diagonal matrix of variances of the unique factor
scores, and the factor pattern matrix of loadings.
Resulting values are then multiplied by the inverse of the
matrix product of the matrices of factor loadings and the
inverse of the diagonal matrix of variances of the unique
factor scores

*EBA*

---
# Goal 3: Working example illustration

- For one individual test scores, how should we make use of our proposed method to explain test results and make clinical decision?

---
## Goal 4: Provide software solution to automate the process 
- R Package 

```r
library("lavaan")
*library("Proposed Package")
model &lt;- 'Gc =~ Gc1 + Gc2 + Gc3
          Gf =~ Gf1 + Gf2 + Gf3
          Gs =~ Gs1 + Gs2 + Gs3
          RD ~~ Gc + Gf + Gs
          RC ~~ Cc + Gf + Gs + RD
          Rf ~~ Gc + Gf + Gs + RD + RC
          '
fit &lt;- sem(model, data=PoliticalDemocracy)#a sem object
#overwrite summary function
summary(obj)
#produce the estimated latent scores and associated ci
*profileProb(obj, given = )
#print unusualness scores (m distance and associated probs)
```
---
&lt;iframe src="https://fengji.shinyapps.io/thesis/" width="100%" height="500px"&gt;&lt;/iframe&gt;
- [Shiny Interface](https://fengji.shinyapps.io/thesis/) (Ideally) 


???
Returning to the IQ, reading and math score question example, we can find the unusualness by calculating d_cM and form `\(\chi^2\)` distribution to understand how unusual the observed individual profile is in a population.
For a more complicated example (see Figure 1), which illustrates the relations between the measures of outcome variables (i.e. Decoding, Reading Comprehension and Reading Fluency) and potential explanatory variables (i.e. Crystallized Intelligence (Gc), Fluid intelligence (Gf), Processing Speed (Gs)) in a structural equation model. With `\(d_cM\)`,we will be able to know the unusualness of the profile of measures of outcome variables given the potential explanatory variables.

---

class: center, middle

# Thanks!

Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).

The chakra comes from [remark.js](https://remarkjs.com), [**knitr**](http://yihui.name/knitr), and [R Markdown](https://rmarkdown.rstudio.com).


A couple of slides were adopted from [Dr. Schneider's past presentation](https://assessingpsyche.wordpress.com/2012/07/08/why-specific-cognitive-processing-weaknesses-are-typically-only-partial-explanations-for-academic-deficits/).
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('showSlide', function (slide) {setTimeout(function() {window.dispatchEvent(new Event('resize'));}, 100)});</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
